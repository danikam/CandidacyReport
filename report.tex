\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{times}
\usepackage{graphicx}
\usepackage{float}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{lineno}
\usepackage{amsmath}
\usepackage{multirow}
\usepackage{bm}
\RequirePackage{booktabs}
%\usepackage{natbib,hyperref}
\linenumbers

\newcommand*{\met}{\ensuremath{E_\text{T}^\text{miss}}}
\newcommand*{\mindphi}{\ensuremath{\Delta \phi_{\text{jets}_{1,2,3} \met}}}
\newcommand*{\metnomu}{\ensuremath{E_\text{T}^{\text{miss}, \text{no} \mu}}}
\newcommand*{\ptll}{\ensuremath{p_{\text{T}}^{\ell \ell}}}

\author{Danika MacDonell}
\title{Search for Dark Matter Produced in Association with a Hypothetical Dark Higgs Boson Decaying to $W^+W^-$ in the $q\bar{q}\ell\nu$ Final State Using $pp$ Collisions Recorded with the ATLAS Detector}
\begin{document}
\maketitle

\section{Introduction}

The proposed thesis is a search for dark matter using high energy proton-proton ($pp$) collision data recorded with the ATLAS detector at the Large Hadron Collider (LHC). The search targets a final state signature of dark matter production in association with the emission of a hypothetical higgs boson $s$ in the dark sector, which subsequently decays to a pair of W bosons. The search is motivated by and optimized with a ``dark higgs model" \cite{dark_higgs} shown in figure \ref{fig:signal_model}, in which the $s$ is emitted from a hypothetical $Z'$ gauge boson in the dark sector, which itself mediates the production of dark matter particles from the high energy $pp$ collisions.

Any dark matter that may be produced in the $pp$ collisions is expected not to interact to any measurable extent with the `normal' matter constituting the detector. As such, it is assumed that the momentum carried by the dark matter would escape the detector undetected. However, the law of momentum conservation requires that the momenta of all particles produced by a $pp$ collision in the plane transverse to the beam line sum to zero. This fundamental requirement implies that dark matter produced at the LHC will exhibit a signature of high missing transverse momentum in the final state. The magnitude of this two dimensional missing transverse momentum vector is typically denoted ``\met". 

The aim of the proposed thesis work is to apply selections, including a requirement of high \met, to data from the ATLAS detector to optimize the sensitivity of the data to the dark higgs signal model. The data will subsequently be compared with standard model (SM) background and signal processes simulated with Monte Carlo (MC) to search for an above-background excess in the data consistent with the signal model. 

The search is split into two separate analyses:

\begin{enumerate}

\item \textbf{The hadronic decay channel:} In this channel, each of the two W bosons in the final state decay to quarks, which subsequently hadronize in the detector and are measured as jets in the ATLAS calorimeter.

\begin{equation}
\nonumber
WW \rightarrow q\bar{q}+q\bar{q}
\end{equation}

Given that the branching fraction for hadronic W decay is 0.68 \cite{PDG}, the fully hadronic WW decay occurs with a branching fraction of 0.46 ($=0.68^2$). In addition to its substantial branching fraction, this channel has the advantage of being able to fully reconstruct the momenta of both W bosons, and as such the $s$ mass. The drawback is that there are standard model processes with large production cross section which also produce a final state of multiple jets in the detector, a subset of which pass the other signal selection criteria and represent a sizeable background in the analysis. 

\item \textbf{The semileptonic decay channel:} One W boson decays to quarks in this channel, and the other decays to a lepton and a neutrino, where the lepton is either an electron or a muon. 

\begin{equation}
\nonumber
WW \rightarrow q\bar{q}+\ell\nu
\end{equation}

Despite its lower branching fraction of 0.29 \cite{PDG} compared with the fully hadronic decay channel, the semileptonic channel has the advantage that the requirement of having one lepton in the final state reduces the background from standard model processes. However, this comes at the cost of additional \met from the neutrino production, which both inhibits reconstruction of the leptonically-decaying W boson and cannot easily be distinguished from the \met associated with dark matter production in the signal model. 

\end{enumerate}

There is an ongoing analysis searching for the dark higgs signal in the hadronic decay channel, and the proposed thesis will focus on the semileptonic decay channel. 

The WW decay can also proceed via a fully leptonic channel, in which both W bosons decay to a lepton and a neutrino. This channel would give a clean signature of two leptons and no jets, but is currently not considered as a viable search channel due to its relatively low branching fraction of 0.046 \cite{PDG}.

Once the analysis is fully developed in the semileptonic decay channel, this channel will be statistically combined with the hadronic search channel. In the event that the combined search does not show an above-background excess, the analysis will place exclusion limits - to within some level of confidence, typically 95\% - on the range of $Z'$ and $s$ masses in the dark higgs model to which the combined search is sensitive.

\section{Motivation}

The proposed thesis work would contribute to the extensive ongoing dark matter search program at the LHC. The LHC search program is motivated by compelling evidence from observational astronomy for the existence of dark matter constituting 85\% \cite{planck} of all matter in the universe. Despite clear evidence from observational astronomy for its gravitational interactions with normal matter, dark matter has yet to be detected through the weak, strong or electromagnetic interactions. As such, its composition and non-gravitational interactions - if any - remain largely a mystery. The current most widely accepted and theoretically motivated dark matter candidates take the form of fundamental particles, yet there is no particle in the standard model of particle physics that could represent a viable dark matter candidate \cite{feng}. Dark matter is therefore widely assumed to be a ``beyond-standard-model" (BSM) particle. 

\subsection{Dark Matter Search Methods}
There are three complementary approaches used to search for particle dark matter: direct and indirect detection, and collider searches. Direct detection searches \cite{Schumann_2019, 2015gya} aim to directly detect evidence of a recoil induced by elastic scattering between a dark matter particle in the galactic halo passing through the detector and a target particle in the detector. Indirect searches \cite{CIRELLI_2012, conrad} use observational data to search for evidence of products produced by dark matter annihilation or decay in particular regions of the observable universe expected to have a high dark matter density. Collider searches \cite{DM_colliders}, of which the proposed thesis work is an example, study the decay products from high-energy collisions of subatomic particles to search for an above-background excess of events that could be consistent with dark matter having been produced in some of the collisions.

\subsection{Models of Dark Matter Production at Colliders}
Models of dark matter production in colliders can range in complexity from an effective field theory (EFT), where the dark matter production mechanism is completely unspecified, to a complete model such as supersymmetry \cite{susy_dm}, which predicts viable dark matter candidates as part of a hypothesized extension to the standard model designed to address a range of phenomena unexplained by the standard model. 

%The EFT approach treats the production of dark matter from colliding partons as a contact interaction, with the production rate determined by a single parameter \cite{DM_colliders}. As long as a measurable standard model particle is also produced in the interaction (eg. a gluon radiating from one of the colliding quarks, see figure \ref{fig:eft_simplified_model}), the EFT framework can be applied to any mono-X signature at the LHC, where a SM particle X is measured along with missing transverse momentum in the detector. This makes the framework generally usable in terms of motivating and providing a theoretical framework to interpret a range of generic search channels that can be readily selected for in LHC collision data. However, the EFT framework relies on the assumption that the the mediator(s) of the interaction is (are) much more massive than the scale of momentum transfer in the interaction \cite{DM_colliders, beyond_eft}. If this assumption is inaccurate, the EFT framework becomes invalid, and a more complete model is needed to specify additional details of the process leading to dark matter pair production. 

\begin{figure}[H]
	\centering
	\begin{minipage}[b]{0.45\textwidth}
	\includegraphics[width=0.9\textwidth]{figures/EFT_Signature.png}
	\end{minipage}
	\begin{minipage}[b]{0.45\textwidth}
	\includegraphics[width=0.8\textwidth]{figures/simplified_model.png}
	\end{minipage}
	\caption[]{Left: Mono-jet process in the EFT framework (source: \cite{beyond_eft}). Right: Mono-jet process in a simplified model framework, where the pair production of dark matter occurs via a new vector or axial-vector ($V$, $A$) mediator of mass $M_\text{med}$, which couples to quarks and dark matter with coupling constants g$_q$ and g$_\text{DM}$, respectively (source: \cite{dm_forum})}
	\label{fig:eft_simplified_model}
\end{figure}

In principle, complete theories of physics beyond the standard model, such as the minimal supersymmetric standard model (MSSM) \cite{mssm} can offer theoretically motivated and experimentally accessible models which specify the details of candidate processes by which the colliding partons may annihilate to produce dark matter. However, these theories tend to be quite complex, with many free parameters - over 100 in the case of MSSM \cite{DM_colliders} - most of which need to be fixed to generate a reasonably testable model. Relying on complete theories alone to guide experimental signatures may run the risk of missing important parameter space of new physics for which a complete theory has not yet been developed. 

Simplified models, widely used in recent and ongoing dark matter searches at the LHC, are designed to bridge the gap between EFT and complete theories. They provide a `first-order' description of theoretically motivated new physics scenarios that could be accessible at collider energies. They provide guidance for experimental searches without fully specifying the details of any additional new physics at energies above the collider scale that would be needed for a complete theory \cite{DM_colliders}. In terms of dark matter production at the LHC, one or more new mediators associated with new physics scenarios may be considered which allow for mixing between standard model particles and dark matter. The process by which the mixing occurs is represented with a tree-level diagram whose experimental signature would be accessible at LHC energies, such as the diagram shown in figure \ref{fig:eft_simplified_model} which represents a dark matter benchmark model featured in the 2015 report of the ATLAS/CMS Dark Matter Forum \cite{dm_forum}.

\subsection{Dark Higgs Model}

The proposed search is motivated by and interpreted with a simplified model described in \cite{dark_higgs} where dark matter is pair produced from a Z boson in the dark sector - known as the $Z'$ boson - in association with the emission of an additional dark sector higgs boson $s$. Figure \ref{fig:signal_model} shows one of the leading order Feynman diagrams representing this simplified model. The dark sector higgs boson subsequently decays to a pair of massive standard model particles through a small mixing with the SM higgs boson. 

\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\textwidth]{figures/Signal_generic.png}
	\caption[]{Dark higgs model}
	\label{fig:signal_model}
\end{figure}

The generic hypothesis of `dark sector' mediators which exhibit a small mixing with SM particles is motivated in part by the theoretical need for creation and annihilation mechanisms between DM and SM particles in the well-motivated and popular `thermal freeze-out' hypothesis \cite{particle_dm}. In the thermal freeze-out hypothesis, DM and SM particles interacted at a sufficient rate in the high temperature and matter density of the early universe to remain in thermal equilibrium. Once the DM-SM interaction rate dropped below the expansion rate of the universe, the DM rapidly ``froze out" of thermal equilibrium with the SM particles, at which point the relic abundance of DM was fixed to the value observed in the present-day universe.

The dark higgs boson in particular is motivated by the need to generate the masses of dark matter and any other particles residing in the dark sector \cite{dark_higgs}. If dark sector particle masses are generated via a `dark sector higgs mechanism', this would naturally imply the existence of a dark higgs boson. 

The model presented in \cite{dark_higgs} considers a scenario in which there is another dark sector mediator - taken to be the $Z'$ - with a mass within the range accessible to measurement at the LHC, which mediates dark matter production from parton collisions. In this case, the $Z'$ could radiate a dark higgs boson. Theoretically, the observed relic abundance of dark matter in the universe suggests that couplings between particles in the dark sector should be quite large, which could result in a sufficiently high probability of dark higgs emission from the $Z'$ to produce a measurable signature in LHC collisions \cite{dark_higgs}. 

Experimentally, the dark higgs signature would be distinct from generic mono-X signatures where the SM particle that the dark matter recoils against is produced via initial state radiation, because as long as the mass of the $s$ is well below the typical momentum transfer of the collisions, the $s$ will tend to be highly boosted in the plane transverse to the beam line. As a result, the SM decay products will tend to be much higher in transverse momentum and highly collimated compared with particles produced via initial state radiation.  

\subsection{Experimental Background}

This section discusses a previous experimental search which set exclusion limits on the dark higgs model described in Section 2.3, in the case where the dark higgs decays to a pair of b quarks. It goes on to describe the m$_s$ range that the ongoing and proposed searches in the $s \rightarrow WW$ decay channel target, and explain how this target is complementary to the m$_s$ range explored by the previous search in the $s \rightarrow bb$ channel. 

\subsubsection{Re-interpretation of Mono-H(bb) Search with a Dark Higgs Mediator}

Last year, the ``mono-H(bb)" dark matter search, originally published in 2018 \cite{monohbb} with 79.8 fb$^{-1}$ of data taken with the ATLAS detector at a 13 TeV centre of mass energy, was re-interpreted \cite{monohbb_recast} using the RECAST framework \cite{recast} to set exclusion limits on the dark higgs model in the case where the dark higgs decays to a pair of b-quarks. 

The mono-H(bb) search selects for a final state of missing transverse energy along with two jets in the calorimeter, both of which must be tagged as having originated from the hadronization of b quarks. When the mono-H(bb) analysis was originally published, it had been developed and interpreted using a simplified model shown in figure \ref{fig:monohbbreinterp} left, in which the dark matter is pair produced from a new pseudoscalar higgs boson, along with the emission of a SM higgs boson, which subsequently decays to two b quarks.  

The original analysis was preserved using RECAST \cite{recast}, a framework designed to preserve searches for new physics with high energy collision data in such a way that the searches can be readily re-analyzed with alternative models of new physics which predict the same final state signature. The RECAST framework was used to re-interpret the mono-H(bb) search using the dark higgs model shown in figure \ref{fig:monohbbreinterp} right, where the dark higgs, whose mass is left as a floating parameter, decays to a pair of b quarks. 

\begin{figure}[H]
	\centering
	\begin{minipage}[b]{0.45\textwidth}
	\includegraphics[width=0.8\textwidth]{figures/monohbb}
	\end{minipage}
	\begin{minipage}[b]{0.45\textwidth}
	\includegraphics[width=0.9\textwidth]{figures/monosbb}
	\end{minipage}
	\caption[]{Left: Leading-order Feynman diagram representing the model used to interpret the mono-H(bb) dark matter search. Right: A leading-order Feynam diagram representing the model used to guide and interpret the mono-s(bb) re-interpretation of the mono-H(bb) search. The dark higgs mediator mass m$_s$ is allowed to float in the dark higgs model.}
	\label{fig:monohbbreinterp}
\end{figure}

The re-interpreted mono-H(bb) search set limits, shown in figure \ref{fig:monosbb_exclusion}, on the phase space of $Z'$ and $s$ masses excluded by the data. To set these exclusion limits, several free parameters in the dark higgs model need to be fixed. Specifically:

\begin{itemize}
\item The dark matter mass m$_\chi$ is fixed to 200 GeV.
\item The constant g$_q$ associated with the coupling of the $Z'$ boson to quarks is fixed to 0.25.
\item The constant g$_\chi$ associated with the coupling of the $Z'$ boson to dark matter is fixed to 1.0.
\item The mixing angle $\theta$ between the dark and SM higgs bosons is fixed to 0.01.
\end{itemize}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{figures/monosbb_exclusion.png}
	\caption[]{Exclusion limits set on the $Z'$ and $s$ mediator masses by the mono-H(bb) search re-interpreted with the dark higgs model. Mass combinations to the left of the solid black curve are excluded at a 95\% confidence level. Source: \cite{monohbb_recast}}
	\label{fig:monosbb_exclusion}
\end{figure}

The values of $g_q$ and $g_\chi$ were chosen to match the conventional choices used by other LHC DM searches, and $\theta$ matches the choice used in the original paper \cite{dark_higgs} that introduced the dark higgs model.

\subsubsection{Dark Higgs Decay Modes}

The re-interpreted mono-H(bb) search probed the dark higgs model in the case where the $s$ emitted from the $Z'$ mediator decays to a pair of b quarks. However, predictions of the dark higgs branching ratio presented in the re-interpretation paper \cite{monohbb_recast} and shown in figure \ref{fig:higgsbrs} indicate that the $s \rightarrow bb$ decay mode is only sensitive to a range of dark higgs masses up to $\sim$150 GeV, above which the WW decay mode dominates in sensitivity. 

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{figures/BR_vs_mass.png}
	\caption[]{Predicted dark higgs decay branching ratios as a function of dark higgs mass. Source: \cite{monohbb_recast} }
	\label{fig:higgsbrs}
\end{figure}

There is no a-priori reason to expect the dark higgs mass m$_s$ to necessarily lie below 150 GeV. Therefore, it's important to probe the model in the higher m$_s$ range by analyzing the $s \rightarrow WW$ decay mode. The proposed thesis work will analyze the latter decay mode using the full 139 fb$^{-1}$ ATLAS run 2 dataset, focusing on the semileptonic final state $WW \rightarrow q\bar{q}\ell\nu$.

\newpage

\section{Introduction to the LHC and the ATLAS detector}

The Large Hadron Collider (LHC) \cite{lhc_machine} is a circular proton-proton collider which resides in a 27 km tunnel near the European Organization for Nuclear Research (CERN). Superconducting magnets are used to accelerate counter-rotating bunched proton beams to high energy, and direct the beams into head-on collisions at four interaction points around the ring. The collisions take place at a world-leading centre of mass energy of up to 13 TeV. 

Each interaction point is surrounded by a detector, which measures the energetic debris of particles produced by the high energy collisions to perform precision measurements of the standard model and search for new physics. ATLAS (A Toroidal LHC ApparatuS) \cite{atlas} is one of two multi-purpose detectors at the LHC, designed to record and study a wide range of physics processes resulting from the collisions. 

The ATLAS detector, shown schematically in figure \ref{fig:detector}, provides full 4$\pi$ coverage around the interaction point, with the exception of the beam pipe. It consists of several layers of sub-detectors, each of which is specialized for recording certain kinematic information and particle types. The sub-detectors are described in some detail below. 

\begin{figure}[H]
	\centering
	\includegraphics[width=0.85\textwidth]{figures/detector.jpg}
	\caption[]{Schematic diagram of the ATLAS detector. Source: \cite{atlas}}
	\label{fig:detector}
\end{figure}

\subsection{The Inner Detector}

The inner detector (ID), located nearest the the beam pipe, is specialized for charged particle tracking. It is immersed in a 2T magnetic field oriented parallel to the beam pipe, which bends the trajectories of electrically charged particles as they pass through the field. Three distinct but complementary tracking technologies are employed along with pattern recognition tools to map the trajectories of charged particles passing through the ID. These reconstructed tracks are a critical component of vertex reconstruction, and the degree of bending and direction of the bent tracks at the production vertex provide information about the momentum, charge, and identity of the charged particles that produced them. 

\subsection{The Calorimeter}

The calorimeter is designed to measure the energy of all particles which pass through it by initiating ``showers" and fully absorbing their energy. The only particles which cannot be absorbed by the calorimeter are muons and neutrinos, which pass through without showering. The calorimeter is divided into two sub-detectors, the electromagnetic and hadronic calorimeters. Both are ``sampling calorimeters", which means they are comprised of repeated layers of dense absorbing material with ``sampling" layers in between. The sampling layers track the location of the shower and record a small fraction of its energy, to which a calibration factor can be applied to infer the full shower energy. 

\subsubsection{Electromagnetic Calorimeter}

The electromagnetic (EM) calorimeter forms the inner calorimeter layer, and is designed to fully absorb and measure the energies of electrons and photons. Energy is deposited in the iron-steel absorbing layers in the form of EM showers \cite{em_showers}, in which the initial electron or photon interacts with the absorbing material to produce a cascade of photon radiation and electron pair production. The sampling layers are filled with liquid argon (LAr), with sensors to measure the ionization produced by charged particles passing through the LAr \cite{em_cal}. 

\subsubsection{Hadronic Calorimeter}

The hadronic calorimeter surrounds the EM calorimeter, and is designed to fully absorb and measure hadronic showers, also known as ``jets", initiated by hadrons, which can make it through the EM calorimeter due to their relatively long interaction length \cite{atlas}. Unlike the EM showers described above which proceed exclusively via electromagnetic interactions, hadronic showers proceed via both the strong and EM interactions, and as a result are in general more variable and less localized. 

The hadronic calorimeter is comprised of a tile calorimeter which encircles the EM calorimeter barrel, and a LAr calorimeter with copper and tungsten absorbers in the end-cap region which encloses the two ends of the barrel. The tile calorimeter uses steel as the absorber material and scintillators read out by photomultiplier tubes (PMTs) in the sampling layers. 

\subsection{The Muon Spectrometer}

The muon spectrometer \cite{atlas} surrounding the calorimeter is specialized for tracking muons and measuring their momentum. It employs the same principle used in the inner detector of applying a strong magnetic field and measuring the resulting bent trajectories of the electrically charged muons passing through to infer their momentum. 

The magnetic field is generated by rectangular superconducting ``toroid magnets" arranged azimuthally in radial planes around the beam axis, which set up a toroidal field concentric to the beam axis. In the region containing the strong field established by the toroid magnets, muon tracks are recorded by three cylindrical layers of muon tracking chambers in the barrel region and three layers of chambers arranged in wheels perpendicular to the beam axis in the end-cap region. Additional layers of fast trigger chambers deliver muon track information to the ATLAS trigger system so it can be incorporated into the event readout decision. 

\newpage

\section{Monte Carlo Simulation of Signal and Background}

To search for evidence of new physics in the ATLAS data, it is necessary to model the number of SM ``background" events that are expected in the data, as well as their distributions in the many observables, such as \met, that can be computed from the raw data. Only the SM processes which are expected to represent statistically significant backgrounds in the signal region are considered in the analysis. The data can then be compared with the SM background model to search for evidence of an excess of events above the SM background which may be consistent with a hypothesized signal model.

Signal and SM background models are generated by sophisticated Monte Carlo simulations, both of the physical production mechanisms and the passage of the final-state particles through the ATLAS detector. 

For a given process, for example the Z+jets background shown in figure \ref{fig:dom_bkgs} left, ``truth-level" information for each MC event is first obtained from a random proton-proton collision by simulating the physical production mechanism for the process. The simulated final state products, along with their kinematic information, are collectively known as the ``truth-level" event. Truth-level events can subsequently be passed through a simulation of the ATLAS detector to statistically model how they would actually be measured by the detector at ``reconstruction-level". 

Given sufficient MC statistics, the kinematic distributions of reconstruction-level events, scaled by the integrated LHC beam luminosity and production cross section for the process, provide a statistical model of how the given process would appear in the ATLAS data.

\section{Ongoing Search for the Dark Higgs Model in the Hadronic Decay Channel}

This section briefly summarizes the ``mono-s(WW)" search for the dark higgs model in the fully-hadronic final state channel, which is currently undergoing approval within the ATLAS collaboration. 

MC simulated samples were generated for the dark higgs model over the grid of dark higgs and Z' boson masses shown in figure \ref{fig:had_grid}. 

 \begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{figures/had_grid.png}
	\caption[]{Grid of signal models generated using MC for the hadronic mono-s(WW) analysis at various dark higgs and Z' boson masses. Red points are simulated with all three possible WW decay channels ($WW \rightarrow qqqq$, $WW \rightarrow qq\ell\nu$ and $WW \rightarrow \ell\nu\ell\nu$) and blue points are simulated exclusively with fully hadronic WW decays ($WW \rightarrow qqqq$) to save computing time.}
	\label{fig:had_grid} 
\end{figure}

\subsection{Signal Region Selection}

\subsubsection{Pre-selection}

Selection cuts are applied to the data and MC samples in the ``signal region" (SR) with the aim of maximizing the sensitivity of the data to the dark higgs signal of interest in the fully hadronic decay channel. To avoid biasing the selection based on features in the data, the SR is `blinded', which means that the cuts are developed and optimized using the signal and background MC alone.

Prior to cut optimization, loose pre-selection cuts are applied to broadly capture the region of interest for the search. The pre-selection cuts used by the hadronic analysis are listed in the first column of Table \ref{tab:eventselection-baseline}, which is taken from the internal support note for the hadronic analysis. 

The first three cuts and the final cut listed in Table \ref{tab:eventselection-baseline} - 0 baseline lepton ($\ell$), \met $>$ 200 GeV, $\tau$ veto and \(N(\text{small-\(R\) jets}) \geq 2\)  - perform the basic selection for a fully hadronic final state with high \met. 

A veto is placed on variable radius (VR) track jets tagged as having been produced from b quarks (i.e. ``b-tagged") is designed to reduce the ``ttbar" background of standard model top quark pair production, as top quarks decay almost exclusively to b quarks. A lower bound of 15 is placed object based \met significance $\mathcal{S}$ with the aim of removing events with high \met originating from poor detector energy resolution. Lastly, to a lower bound of 0.35 is placed on the angular separation between the leading 3 small-radius jets and the \met to select for the desired topology of dark matter recoiling against jets. 

\begin{table}[ht]
    \centering
    \caption{The baseline selection which is required in all the signal and control regions.}
    \label{tab:eventselection-baseline}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{ccc}
    \toprule
    0 \(\ell\) SR & 1 \(\mu\) control region & 2 \(\ell\) control region \\ \midrule
    0 baseline \(\ell\) & 0 baseline e,  1 baseline+signal \(\mu\) & 2 baseline+signal \(ee\) / opposite sign \(\mu^{+} \mu^{-}\) \\
    \met $>$ 200 GeV  & \metnomu $>$ 200 GeV & \ptll $>$ 200 GeV\\
    \(\tau\) veto & \(\tau\) veto & \(\tau\) veto \\
    0 \(b\)-tagged VR track jets in event & 0 \(b\)-tagged VR track jets in event & 0 \(b\)-tagged VR track jets in event\\
    VR track jet \(\Delta R\) overlap veto & VR track jet \(\Delta R\) overlap veto & VR track jet \(\Delta R\) overlap veto \\
    \(\mindphi > 0.35\) & \(\mindphi > 0.35\) & - \\

    \(\mathcal{S} > 15\) & \(\mathcal{S} > 15\) & \(\mathcal{S} < 15\) \\
    \(N(\text{small-\(R\) jets}) \geq 2\) &  \(N(\text{small-\(R\) jets}) \geq 2\) &  \(N(\text{small-\(R\) jets}) \geq 2\)
    \\ \bottomrule
    \end{tabular}}
\end{table}

\subsubsection{Kinematic Categories}

In addition to the pre-selection cuts described in Section 4.1.1, further selections are optimized separately in the three kinematic categories illustrated in figure \ref{fig:had_categories}, known as ``merged", ``intermediate" and ``resolved". 

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.29\textwidth}
         \centering
         \includegraphics[width=0.95\textwidth]{figures/had_merged.png}
         \caption[]{Merged category}
         \label{fig:had_merged}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.29\textwidth}
         \centering
         \includegraphics[width=0.95\textwidth]{figures/had_int.png}
         \caption[]{Intermediate category}
         \label{fig:had_int}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.29\textwidth}
         \centering
         \includegraphics[width=0.95\textwidth]{figures/had_resolved.png}
         \caption[]{Resolved category}
         \label{fig:had_resolved}
     \end{subfigure}
\caption[]{Illustration of the kinematic categories used for event selection optimization in the analysis of the mono-s(WW) hadronic channel. Source: Adapted from a figure shown by P. Gadow in an ATLAS internal approval presentation. }
\label{fig:had_categories}
\end{figure}

The ``merged" category represents regime in which the hadronic final state is sufficiently boosted in the transverse plane that the quark hadronizations identified as having originated from the hadronic WW decays cannot be individually resolved, and are instead reconstructed as a single large-radius jet. In the ``resolved" category, the boost is sufficiently small that all four quark hadronizations identified as having originated from W decays can be resolved into individual jets. In between these two extremes is the ``intermediate" category, which is characterized by two or three of the hadronized quarks being reconstructed together as a large-R jet and the others being resolved into individual jets.

\subsection{Control regions}

Control regions (CRs) are designed to provide data-driven normalization constraints for the dominant Z+jets and W+jets standard model background processes, shown in figure \ref{fig:dom_bkgs}. The CR is chosen by selecting a region of phase space that is kinematically similar to the SR, and which contains a high purity of the background process to be normalized. The CR must be orthogonal to the SR to avoid unblinding any part of the SR. To minimize the possibility of any signal events in the data affecting the normalization of the standard model background process, it is also desirable to select a CR in which negligible contamination of the MC signal events is observed. Data and MC distributions are compared in the intermediate kinematic category of the two CRs in figure \ref{fig:had_Intermediate_DataMC}. 

\begin{figure}[H]
	\centering
	\includegraphics[width=\textwidth]{figures/had_Intermediate_DataMC.png}
	\caption[]{Data-MC comparisons of reconstructed dark higgs candidate mass distributions in the intermediate kinematic category of the 1-lepton (left) and 2-lepton (right) CRs}
	\label{fig:had_Intermediate_DataMC} 
\end{figure}

\subsubsection{1 Lepton CR}

The 1 lepton CR is identical to the SR, except that the lepton veto is replaced by requirement of one signal muon. This CR is designed to obtain a purified sample of the SM W+jets background in which the \met arises from a neutrino produced in the leptonic decay of a W boson, and thereby provide a constraint on the normalization of this background process. In the fully hadronic signal region, the lepton in this process is not properly reconstructed, and escapes detection. 

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.9\textwidth]{figures/Zjet_feynman.png}
         \caption[]{Z+jets}
         \label{fig:zjets}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.9\textwidth]{figures/Wjet_feynman.png}
         \caption[]{W+jets}
         \label{fig:wjets}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.9\textwidth]{figures/ttbar_feynman.png}
         \caption[]{$t\bar{t}$}
         \label{fig:ttbar}
     \end{subfigure}
\caption[]{Dominant SM background processes for the mono-s(WW) search. The Z+jets background is only dominant in the hadronic channel, as it is significantly reduced by the 1-lepton requirement in the semileptonic channel.}
\label{fig:dom_bkgs}
\end{figure}
\subsubsection{2 Lepton CR}

The 2 lepton CR is also largely identical to the SR. The primary difference is the replacement of the lepton veto by a requirement of two signal muons or electrons. This CR is designed to obtain a purified sample of the Z+jets background produced by the leptonic decay of a Z boson. This is used to obtain a normalization for the Z+jets background where the Z boson decays hadronically in the signal region. In addition to the two-lepton requirement, the MET significance is reversed and the \mindphi cut is removed to boost the contribution from QCD background. 

\subsection{Systematic Uncertainties}

In addition to the statistical uncertainty arising from the limited number of events present in the data and simulated in the Monte Carlo, systematic uncertainties arising from both theoretical and experimental sources which can affect the normalization and shape of observables used in the analysis. These systematic uncertainties are accounted for in the analysis by evaluating the effects of variations in the Monte Carlo generated samples arising from parameters in the MC production being varied from their nominal values by their respective systematic uncertainty. 

\subsubsection{Experimental systematics}

Experimental systematic uncertainties arising from various aspects of modelling the ATLAS detector and LHC machine are provided by the relevant ATLAS performance groups. These include the limited precision of the LHC beam luminosity, uncertainties associated with lepton and muon reconstruction and identification, and jet energy resolution. Uncertainties associated with the reconstruction of the missing transverse momentum are also considered. 

\subsubsection{Theoretical Modelling Uncertainties}

Theoretical modelling uncertainties associated with the generation of Monte Carlo samples for both signal and the dominant Z+jets and W+jets SM background processes are also evaluated and incorporated in the analysis. Variations arising from the modelling of the parton density functions (PDFs) \cite{PDG_PDF} of the colliding protons are considered, along with the renormalization and factorization scales \cite{PDG_QCD} used to model QCD processes. 

For the W+jets and Z+jets background processes, which are nominally modelled with the SHERPA generator \cite{SHERPA} the variation arising from generating the events with an alternative event generator called PYTHIA 8 \cite{PYTHIA8} are also considered. The alternative generator uses a different algorithm to model parton showering, with all other settings in the alternative generator kept the same. 

\subsection{Sensitivity Estimates}

To estimate the analysis sensitivity for the hadronic channel, the data is binned in \met and dark higgs candidate mass. Mock binned data is generated for each signal point to be statistically consistent with the simulated SM background, and is subsequently fit to the SM background and signal model for events passing the event selection criteria. The W+jets and Z+jets background shapes are obtained in the fit from Monte Carlo, and their normalization factors from the 1-lepton and 2-lepton CRs, respectively. 

The fit is used to obtain a CLs value \cite{PDG_stats} for each signal point, which can also be expressed as a ``significance" by treating the CLs as a p-value and computing the corresponding standard deviation from the null hypothesis. Signal points with CLs value below 0.05, or significance above 1.96, could be excluded for the hypothesized production cross section with 95\% confidence if the data is statistically consistent with the background. 

\begin{figure}[H]
     \centering
     \includegraphics[width=0.6\textwidth]{figures/had_sensitivity.png}
     \caption[]{Hadronic channel with all analysis regions and systematic uncertainties}
\caption[]{Sensitivity estimate for hadronic channel, expressed in terms of significance. The fit includes all analysis regions and systematic uncertainties.}
\label{fig:sensitivity}
\end{figure}

\section{Signal Sample Generation}

\subsection{Parameter Choices}

MC signal samples for the dark higgs model with s$\rightarrow$WW decay are generated over a range of m($s$) and m($Z'$) for which the analysis is expected to be sensitive to the model. There are several other free parameters in the dark higgs model which need to be fixed to perform the scan. 

\begin{itemize}
	\item Coupling $g_{q}$ of the Z' boson to quarks: 1 
	\item Coupling $g_{\chi}$ of the Z' boson to dark matter: 0.25
	\item Dark matter mass $m_{\chi} = 200$ GeV
	\item Mixing angle $\theta$ between the SM and dark sector higgs bosons: 0.01
\end{itemize}

The values of $g_q$, $g_\chi$ and $m_\chi$, listed above, are chosen to match the choices used for other LHC searches for ease of comparison, and the value of $\theta$ is chosen at the suggestion of the authors of the phenomenology paper \cite{dark_higgs} in which the model is introduced. 

\subsection{Semileptonic Signal Grid}

A signal grid has been generated for the mono-s(WW) signal with semileptonic WW decay, presently at the same points as were generated with hadronic decay for the hadronic analysis described above. There are additionally two signal points generated with all possible WW decay modes (i.e. `inclusive'). 

Work is ongoing to re-generate the grid with a more recent release of the ATLAS simulation software, and extend it as shown in Fig. ~\ref{fig:signalgrid} to allow for a more complete coverage of the phase space region to which the analysis could be sensitive.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{figures/SignalGrid_simple.png}
	\caption[]{Grid of signal points with respect to dark higgs (s) and $Z'$ boson masses}
	\label{fig:signalgrid}
\end{figure}

\section{Event Selection for Semileptonic Channel}

This section describes the current event selection used to optimize the sensitivity of the analysis to the dark higgs signal with semileptonic WW decay. 

\subsection{Preselection}

As was done for the hadronic analysis, several pre-selection cuts are applied to broadly define the channel prior to further cut optimization. The current pre-selection cuts are listed below.

\begin{itemize}
\item Event passes \met trigger
\item 1 signal muon or 1 signal electron
\item \met $>$ 150 GeV
\end{itemize}

In addition to the current preselection cuts, the following two cuts are common to both categories, and may become listed as pre-selection in the future:

\begin{itemize}
\item Veto on b-tagged jets
\item Lepton-\met transverse mass $m_T(\ell, \met)$ $>$ 150 GeV
\end{itemize}

The transverse mass $m_T(\met, \ell)$ between the lepton and \met is considered in the semileptonic channel, because it is sensitive to additional \met on top of that arising from the neutrino in the semileptonic W decay. It is computed in the ATLAS data and MC as:

\begin{equation}
m_T(\ell, \met) = \sqrt{2p_{T, \ell}, \met(1-\cos\theta_{\ell, \met})}
\end{equation}
which comes from the full transverse mass definition \cite{PDG_kin}

\begin{equation}
m_{T, \text{ full}}(\ell, \met)^2 = (E_{T, \ell}^2 + E_{T, \met}^2 - (p_{T, \ell}^2 + p_{T, \met}^2)) 
\end{equation}

$$
= m_\ell^2+m_{\met}^2 + 2E_{T, \ell}, E_{T, \met}(1-\cos\theta_{\ell, \met})
$$
under the assumptions that the masses of the lepton and \met are negligibly small compared with their momenta. The assumption of negligible lepton mass is in general justified given the energy of LHC collisions. The assumption of negligible \met mass is justified if the true \met arises only from the neutrino in the semileptonic W, as it would in the leading SM backgrounds, but not in the signal model which has additional \met mass arising from dark matter production. The result, shown in figure \ref{fig:mT_lep_met}, is that the bulk of the SM background has $m_T(\ell, \met)$ below the W mass peak, but the signal distribution tends to be peaked closer to $\sim$250 GeV. 

\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\textwidth]{figures/mT_lep_met_preselection.png}
	\caption[]{Transverse mass distribution for SM background and several signal points with pre-selection cuts}
	\label{fig:mT_lep_met}
\end{figure}

\subsection{Kinematic Categories}

Further cuts are optimized within the two kinematic categories illustrated in figure \ref{fig:lep_categories}. As for the hadronic analysis, the kinematic category definitions aim to characterize the degree to which the leading hadronic jets in the event are boosted. The ``merged" category aims to capture the highly boosted regime, in which the final state is sufficiently boosted in the transverse plane that the leading hadronic showers are reconstructed as a single large-radius jet. The ``resolved" category captures the regime in which all hadron showers have a low enough boost as to be individually reconstructed as small-radius jets. 

The intermediate category used in the hadronic analysis, characterized by a combination of large- and small-radius jets, is not considered for the semileptonic channel because the semileptonic WW decay in the signal model produces only two final-state quarks. 

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.9\textwidth]{figures/merged.png}
         \caption[]{Merged category}
         \label{fig:merged}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.4\textwidth}
         \centering
         \includegraphics[width=0.9\textwidth]{figures/resolved.png}
         \caption[]{Resolved category}
         \label{fig:resolved}
     \end{subfigure}
\caption[]{Kinematic categories for the semileptonic WW decay channel}
\label{fig:lep_categories}
\end{figure}

The current merged and resolved category cut definitions, listed and discussed in tables \ref{tab:merged_cuts} and \ref{tab:resolved_cuts}, respectively, have been developed and optimized by two other members of the analysis team. The \met distributions for each category are shown in figure \ref{fig:met_categories}. There is ongoing work within the analysis team to investigate the benefit of tuning the selection further by optimizing the selections within the $WW\rightarrow qqe\nu$ and $WW\rightarrow qq\mu\nu$ decay channels separately.

\begin{figure}[H]
     \centering
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/MetTST_met_merged.png}
         \caption[]{Merged category}
         \label{fig:merged}
     \end{subfigure}
     \hfill
     \begin{subfigure}[b]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{figures/MetTST_met_resolved.png}
         \caption[]{Resolved category}
         \label{fig:resolved}
     \end{subfigure}
\caption[]{\met distributions in the SR in the two kinematic categories developed for the semileptonic WW decay channel. Signals shown with amplitudes multiplied by a factor of 5.}
\label{fig:lep_categories}
\end{figure}

\begin{table}[H]
\centering
\caption{Current data selection cuts in the \textbf{merged} category of the semileptonic decay channel}
\label{tab:merged_cuts}
\begin{footnotesize}
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|p{50mm}|p{100mm}|}
\hline
\textbf{Selection} & \textbf{Discussion}  \\ \hline
At least 1 large-radius jet & -      \\ \hline
\met $>$ 300 GeV      & -      \\ \hline
Reconstructed mass of large-radius jet $\in$ [60 GeV, 100 GeV]     & Increases the likelihood that selected large-R jet originates from a W boson        \\ \hline
\met significance $>$ 15    & \met significance gives a measure of the likelihood that the observed \met arises from true \met due to invisible particles, rather than from fluctuations associated with limited detector resolution.        \\ \hline
$\Delta R(\ell$, large-R jets) $<$ 1.6    & $\Delta R = \sqrt{\Delta\phi^2+\Delta\eta^2}$ is the angular distance between the lepton and the large-radius jet, where $\Delta\phi$ is the angular separation in the transverse plane and pseudorapidity $\eta$ is a quantity related to the angle $\theta$ of a particle relative to the beam axis: $\eta=-\ln\Big[\tan\Big(\frac{\theta}{2}\Big)\Big]$. Pseudorapidity is used rather than $\theta$ because differences $\Delta\eta$ in pseudorapidity are invariant under lorentz boosts. An upper bound is placed on the angular distance to select for the boosted topology of interest, in which all decay products of the dark higgs boson are boosted in approximately the same direction.      \\ \hline
$D_{2}$ of leading large-R jet $<$ 1.4   & The $D_{2}$ variable \cite{Marzani_2019} uses energy correlation functions to give a measure of the likelihood that a jet contains only two spatially separated energy sources. This allows the semileptonic signal channel - in which only two dominant energy sources (i.e. ``prongs") would be expected due to the $W\rightarrow qq$ decay - to be separated from the QCD background which may contain many such prongs.     \\ \hline
\end{tabular}
\end{footnotesize}
\end{table}

\begin{table}[H]
\centering
\caption{Current data selection cuts in the \textbf{resolved} category of the semileptonic decay channel}
\label{tab:resolved_cuts}
\begin{footnotesize}
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|p{50mm}|p{100mm}|}
\hline
\textbf{Selection} & \textbf{Discussion}  \\ \hline
At least 2 small-radius jets & -     \\ \hline
Reconstructed mass of the $W$ candidate $\in$ [60 GeV, 100 GeV]     & The W candidate is selected by considering all combinations of small-radius jets, and identifying the pair whose reconstructed mass is closest to the W boson mass of $\sim$80 GeV.        \\ \hline
\met significance $>$ 13    & -        \\ \hline
$m_T(\ell, \met)$ $>$ 200 GeV    & -        \\ \hline
 $W$ candidate $p_T$ $>$ 100 GeV    & The lower bound on W candidate $p_T$ increases the likelihood that the two jets used to reconstruct the W boson actually originated from the decay of a boosted parent particle.   \\ \hline
$\Delta R(W, \ell) < 1$   & An upper bound on the angular distance between the $W$ boson candidate and the lepton selects for the topology of interest in which one of the boosted $W$ bosons decays leptonically, such that in the lab frame, the lepton is expected to be measured in approximately the same direction as the reconstructed $W$.   \\ \hline
\end{tabular}
\end{footnotesize}
\end{table}

\subsection{W+jets Control Region}

The W+jets control region is defined with the aim of providing a data-driven estimate of the normalization of the W+jets background, illustrated in figure ~\ref{fig:wjets} in the signal region. The exact definition of this control region is still being studied and optimized, but at its simplest, it would simply reverse the transverse mass cut: 

$$
m_T(\ell, \met)>150\text{ GeV} \rightarrow m_T(\ell, \met)\leq 150\text{ GeV}
$$

This reversal makes the W+jets CR orthogonal to the SR, and aims to boost the statistics and purity of the W+jets background without drastically changing the kinematics of the region. Table ~\ref{tab:crw_info} shows that the $m_T(\ell, \met)$ cut reversal improves the W+jets purity and vastly reduces the signal contamination, but only improves the W+jets statistics in the resolved category.

\begin{table}[H]
\centering
\caption{Comparison of W+jets statistics and purity, as well as signal contamination, for SR and preliminary W+jets CR. Signal contamination is averaged over all signal points, and the uncertainty is the standard deviation among all points.}
\label{tab:crw_info}
\begin{footnotesize}
\renewcommand{\arraystretch}{1.5}
\begin{tabular}{|p{30mm}|p{25mm}|p{25mm}|p{45mm}|}
\hline
\textbf{Region} & \textbf{W+jets Statistics} & \textbf{W+jets Purity} & \textbf{Mean Signal Contamination}   \\ \hline
Merged SR    & 59.1 & 65.2\% & 31\% $\pm$ 11\%        \\ \hline
Resolved SR    & 337 & 56.8\% & 13\% $\pm$ 12\%        \\ \hline
Merged W+jets CR    & 53.8 & 78.5\% & 0.49\% $\pm$ 0.30\%        \\ \hline
Resolved W+jets CR    & 704 & 83.4\% & 0.082\% $\pm$ 0.080\%        \\ \hline
\end{tabular}
\end{footnotesize}
\end{table}

Additional cut reversals are being considered to further boost the statistics and purity of the W+jets background in this CR, but careful study is needed to determine whether the region remains sufficiently representative of the SR with these additional cut reversals to provide a reliable normalization factor to be applied to the SR. 

\subsection{$\bm{t\bar{t}}$ Control Region}

An additional CR is being considered, but has yet to be studied, to constrain the second-to-most dominant $t\bar{t}$ background. At its simplest, this CR would simply reverse the b-jet veto, which is primarily intended to reduce the $t\bar{t}$ background in the SR: 

$$
\text{N(b-tagged jets)} <1 \rightarrow \text{N(b-tagged jets)} \geq1
$$

\newpage

\section{Sensitivity Studies for the Semileptonic channel}

Preliminary sensitivity studies have been performed for the semileptonic decay channel using the HistFitter statistical analysis framework \cite{Baak:2014wma}. 
\subsection{Background on limit setting}

\subsection{HistFitter setup}
\begin{itemize}
\item Fit variable
\item Binning
\item Use of temporary systematics proxy
\end{itemize}
\subsection{Preliminary sensitivity limits}
\begin{itemize}
\item Resolved 
\item Merged 
\item Combined
\end{itemize}

\section{Remaining Work and Outlook}
\begin{itemize}
\item Study variables to help address $p_\nu$ vs. $p_{\chi\bar{\chi}}$ MET ambiguity
\item Finalize SR and CR definitions
\item Experimental and modeling systematics
\item Finalize sensitivity estimates with final systematics
\item Statistical combination with hadronic channel for combined limits
\end{itemize}

\newpage

\bibliography{bibliography}
\bibliographystyle{unsrt}

\end{document}